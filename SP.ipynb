{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1: Importation des bibliothèques nécessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2: Chargement des données\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "print(\"Aperçu des données d'entraînement :\")\n",
    "print(train_data.head())\n",
    "\n",
    "print(\"\\nInformations sur les données d'entraînement :\")\n",
    "print(train_data.info())\n",
    "\n",
    "print(\"\\nValeurs manquantes par colonne :\")\n",
    "print(train_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3: Visualisation des données manquantes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(train_data.isnull(), cbar=False, cmap='viridis')\n",
    "plt.title(\"Carte des valeurs manquantes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4: Visualisation initiale des données\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='Transported', data=train_data, palette='viridis')\n",
    "plt.title(\"Distribution des passagers transportés\")\n",
    "plt.show()\n",
    "\n",
    "sns.countplot(x='HomePlanet', hue='Transported', data=train_data, palette='viridis')\n",
    "plt.title(\"Transported par planète d'origine (HomePlanet)\")\n",
    "plt.show()\n",
    "\n",
    "sns.countplot(x='Destination', hue='Transported', data=train_data, palette='viridis')\n",
    "plt.title(\"Transported par destination\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.histplot(train_data['Age'], kde=True, bins=30, color='blue')\n",
    "plt.title(\"Distribution de l'âge\")\n",
    "plt.show()\n",
    "\n",
    "train_data['TotalSpending'] = train_data[['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']].sum(axis=1)\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.histplot(train_data['TotalSpending'], kde=True, bins=30, color='green')\n",
    "plt.title(\"Distribution des dépenses totales\")\n",
    "plt.show()\n",
    "\n",
    "sns.countplot(x='CryoSleep', hue='Transported', data=train_data, palette='coolwarm')\n",
    "plt.title(\"Transported selon CryoSleep\")\n",
    "plt.show()\n",
    "\n",
    "train_data['Deck'] = train_data['Cabin'].str.split('/', expand=True)[0]\n",
    "sns.countplot(x='Deck', hue='Transported', data=train_data, palette='viridis')\n",
    "plt.title(\"Transported par deck\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5: Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remplir HomePlanet avec la valeur modale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_frequent_homeplanet = train_data['HomePlanet'].mode()[0]\n",
    "train_data['HomePlanet'] = train_data['HomePlanet'].fillna(most_frequent_homeplanet)\n",
    "test_data['HomePlanet'] = test_data['HomePlanet'].fillna(most_frequent_homeplanet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CryoSleep : Remplir les valeurs manquantes par False après conversion en booléen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['CryoSleep'] = train_data['CryoSleep'].astype('bool').fillna(False)\n",
    "test_data['CryoSleep'] = test_data['CryoSleep'].astype('bool').fillna(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cabin : Extraire Deck et remplir les valeurs manquantes par 'Unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Deck'] = train_data['Cabin'].str.split('/', expand=True)[0]\n",
    "test_data['Deck'] = test_data['Cabin'].str.split('/', expand=True)[0]\n",
    "train_data['Deck'] = train_data['Deck'].fillna('Unknown')\n",
    "test_data['Deck'] = test_data['Deck'].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Destination : Remplir les valeurs manquantes par la valeur modale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_frequent_destination = train_data['Destination'].mode()[0]\n",
    "train_data['Destination'] = train_data['Destination'].fillna(most_frequent_destination)\n",
    "test_data['Destination'] = test_data['Destination'].fillna(most_frequent_destination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age : Remplir les valeurs manquantes par la médiane*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_age = train_data['Age'].median()\n",
    "train_data['Age'] = train_data['Age'].fillna(median_age)\n",
    "test_data['Age'] = test_data['Age'].fillna(median_age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VIP : Remplir les valeurs manquantes par False après conversion en booléen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['VIP'] = train_data['VIP'].astype('bool').fillna(False)\n",
    "test_data['VIP'] = test_data['VIP'].astype('bool').fillna(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dépenses : Remplir les valeurs manquantes par 0 pour RoomService, FoodCourt, ShoppingMall, Spa, VRDeck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "expenditures = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "for col in expenditures:\n",
    "    train_data[col] = train_data[col].fillna(0)\n",
    "    test_data[col] = test_data[col].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supprimer Name car elle n'est pas pertinente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.drop(columns=['Name'])\n",
    "test_data = test_data.drop(columns=['Name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Créer TotalSpending (Somme des dépenses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['TotalSpending'] = train_data[expenditures].sum(axis=1)\n",
    "test_data['TotalSpending'] = test_data[expenditures].sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculer GroupSize (taille du groupe à partir de PassengerId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['GroupSize'] = train_data['PassengerId'].apply(lambda x: int(x.split('_')[0]))\n",
    "test_data['GroupSize'] = test_data['PassengerId'].apply(lambda x: int(x.split('_')[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6:  Finalisation du prétraitement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Aperçu des données prétraitées (entraînement) :\")\n",
    "print(train_data.head())\n",
    "\n",
    "print(\"\\nAperçu des données prétraitées (test) :\")\n",
    "print(test_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Transformation des variables catégoriques en numériques\n",
    "train_data = pd.get_dummies(train_data, columns=['HomePlanet', 'Destination', 'Deck'], drop_first=True)\n",
    "test_data = pd.get_dummies(test_data, columns=['HomePlanet', 'Destination', 'Deck'], drop_first=True)\n",
    "\n",
    "# Alignement des colonnes entre les deux datasets\n",
    "train_data, test_data = train_data.align(test_data, join='left', axis=1, fill_value=0)\n",
    "\n",
    "# Définir X (caractéristiques) et y (cible)\n",
    "features = ['Age', 'CryoSleep', 'VIP', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck', 'TotalSpending', 'GroupSize']\n",
    "X = train_data[features]\n",
    "y = train_data['Transported'].astype(int)\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement et de validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7: Entraînement du modèle XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "model = XGBClassifier(random_state=42, n_estimators=100, max_depth=10, learning_rate=0.1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Évaluation du modèle\n",
    "y_pred = model.predict(X_val)\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(f\"Accuracy sur l'ensemble de validation : {accuracy:.2f}\")\n",
    "\n",
    "print(\"\\nRapport de classification :\")\n",
    "print(classification_report(y_val, y_pred))\n",
    "\n",
    "# Prédictions sur l'ensemble de test\n",
    "test_data['Transported'] = model.predict(test_data[features]).astype(bool)\n",
    "\n",
    "# Création du fichier de soumission\n",
    "submission = test_data[['PassengerId', 'Transported']]\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"Fichier de soumission 'submission.csv' généré.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialisation du modèle Random Forest\n",
    "rf_model = RandomForestClassifier(random_state=42, n_estimators=100, max_depth=10)\n",
    "\n",
    "# Entraîner le modèle sur l'ensemble d'entraînement\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Prédictions sur l'ensemble de validation\n",
    "rf_y_pred = rf_model.predict(X_val)\n",
    "\n",
    "# Calcul de l'accuracy\n",
    "rf_accuracy = accuracy_score(y_val, rf_y_pred)\n",
    "print(f\"Accuracy avec Random Forest : {rf_accuracy:.2f}\")\n",
    "\n",
    "# Rapport de classification\n",
    "print(\"\\nRapport de classification (Random Forest) :\")\n",
    "print(classification_report(y_val, rf_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9: Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Initialisation du modèle Gradient Boosting\n",
    "gb_model = GradientBoostingClassifier(random_state=42, n_estimators=100, learning_rate=0.1, max_depth=10)\n",
    "\n",
    "# Entraînement du modèle\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Prédictions sur l'ensemble de validation\n",
    "gb_y_pred = gb_model.predict(X_val)\n",
    "\n",
    "# Calcul de l'accuracy\n",
    "gb_accuracy = accuracy_score(y_val, gb_y_pred)\n",
    "print(f\"Accuracy avec Gradient Boosting : {gb_accuracy:.2f}\")\n",
    "\n",
    "# Rapport de classification\n",
    "print(\"\\nRapport de classification (Gradient Boosting) :\")\n",
    "print(classification_report(y_val, gb_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation du modèle Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialisation du modèle Logistic Regression\n",
    "lr_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "# Entraîner le modèle sur l'ensemble d'entraînement\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Prédictions sur l'ensemble de validation\n",
    "lr_y_pred = lr_model.predict(X_val)\n",
    "\n",
    "# Calcul de l'accuracy\n",
    "lr_accuracy = accuracy_score(y_val, lr_y_pred)\n",
    "print(f\"Accuracy avec Logistic Regression : {lr_accuracy:.2f}\")\n",
    "\n",
    "# Rapport de classification\n",
    "print(\"\\nRapport de classification (Logistic Regression) :\")\n",
    "print(classification_report(y_val, lr_y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11: LightGMB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation de LightGBM\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Initialisation du modèle LightGBM\n",
    "lgbm_model = LGBMClassifier(random_state=42, n_estimators=200, learning_rate=0.05, max_depth=-1, num_leaves=31)\n",
    "\n",
    "# Entraîner le modèle sur l'ensemble d'entraînement\n",
    "lgbm_model.fit(X_train, y_train)\n",
    "\n",
    "# Prédictions sur l'ensemble de validation\n",
    "lgbm_y_pred = lgbm_model.predict(X_val)\n",
    "\n",
    "# Calcul de l'accuracy\n",
    "lgbm_accuracy = accuracy_score(y_val, lgbm_y_pred)\n",
    "print(f\"Accuracy avec LightGBM : {lgbm_accuracy:.2f}\")\n",
    "\n",
    "# Rapport de classification\n",
    "print(\"\\nRapport de classification (LightGBM) :\")\n",
    "print(classification_report(y_val, lgbm_y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12: Stacking Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des bibliothèques nécessaires\n",
    "from sklearn.ensemble import StackingClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Définir les modèles de base\n",
    "base_models = [\n",
    "    ('random_forest', RandomForestClassifier(random_state=42, n_estimators=100, max_depth=10)),\n",
    "    ('gradient_boosting', GradientBoostingClassifier(random_state=42, n_estimators=100, max_depth=10, learning_rate=0.1)),\n",
    "    ('lightgbm', LGBMClassifier(random_state=42, n_estimators=100, learning_rate=0.1, max_depth=-1, num_leaves=31))\n",
    "]\n",
    "\n",
    "# Définir le méta-modèle\n",
    "meta_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "# Initialisation du Stacking Classifier\n",
    "stacking_model = StackingClassifier(estimators=base_models, final_estimator=meta_model, cv=5)\n",
    "\n",
    "# Entraîner le modèle sur l'ensemble d'entraînement\n",
    "stacking_model.fit(X_train, y_train)\n",
    "\n",
    "# Prédictions sur l'ensemble de validation\n",
    "stacking_y_pred = stacking_model.predict(X_val)\n",
    "\n",
    "# Calcul de l'accuracy\n",
    "stacking_accuracy = accuracy_score(y_val, stacking_y_pred)\n",
    "print(f\"Accuracy avec Stacking Classifier (avec LightGBM) : {stacking_accuracy:.2f}\")\n",
    "\n",
    "# Rapport de classification\n",
    "print(\"\\nRapport de classification (Stacking Classifier avec LightGBM) :\")\n",
    "print(classification_report(y_val, stacking_y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La méthode LightGBM est la plus intéressaante dans notre cas d'usage, elle retourne les meilleurs résultats ainsi qu'un temps très compétitif.`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
